{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors\n",
    "Vectors, and vector spaces, are fundamental to *linear algebra*, and they're used in many machine learning models. Vectors describe spatial lines and planes, enabling you to perform calculations that explore relationships in multi-dimensional space.\n",
    "\n",
    "## What is a Vector\n",
    "At its simplest, a vector is a numeric element that has both *magnitude* and *direction*. The magnitude represents a distance (for example, \"2 miles\") and the direction indicates which way the vector is headed (for example, \"East\"). Vectors are defined by an n-dimensional coordinate that describe a point in space that can be connected by a line from an arbitrary origin.\n",
    "\n",
    "That all seems a bit complicated, so let's start with a simple, two-dimensional example. In this case, we'll have a vector that is defined by a point in a two-dimensional plane: A two dimensional coordinate consists of an *x* and a *y* value, and in this case we'll use **2** for *x* and **1** for *y*.\n",
    "\n",
    "Our vector can be written as **v**=(2,1), but more formally we would use the following notation, in which the dimensional coordinate values for the vector are shown as a matrix:\n",
    "\\begin{equation}\\vec{v} = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "So what exactly does that mean? Well, the coordinate is two-dimensional, and describes the movements required to get to the end point (of *head*) of the vector - in this case, we need to move 2 units in the *x* dimension, and 1 unit in the *y* dimension. Note that we don't specify a starting point for the vector - we're simply describing a destination coordinate that encapsulate the magnitide and direction of the vector. Think about it as the directions you need to follow to get to *there* from *here*, without specifying where *here* actually is!\n",
    "\n",
    "It can help to visualize the vector, and with a two-dimensional vector, that's pretty straightforward. We just define a two-dimensional plane, choose a starting point, and plot the coordinate described by the vector relative to the starting point.\n",
    "\n",
    "Run the code in the following cell to visualize the vector **v** (which remember is described by the coordinate (2,1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll use a numpy array for our vector\n",
    "v = np.array([2,1])\n",
    "\n",
    "# and we'll use a quiver plot to visualize it.\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, *v, scale=10, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use a numpy array to define the vector in Python; so to create our (2,1) vector, we simply create a numpy array with the elements [2,1]. We've then used a quiver plot to visualize the vector, using the point 0,0 as the starting point (or *origin*). Our vector of (2,1) is shown as an arrow that starts at 0,0 and moves 2 units along the *x* axis (to the right) and 1 unit along the *y* axis (up)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Vector Magnitude and Direction\n",
    "We tend to work with vectors by expressing their components as *cartesian coordinates*; that is, *x* and *y* (and other dimension) values that define the number of units travelled along each dimension. So the coordinates of our (2,1) vector indicate that we must travel 2 units along the *x* axis, and *1* unit along the *y* axis.\n",
    "\n",
    "However, you can also work with verctors in terms of their *polar coordinates*; that is coordinates that describe the magnitude and direction of the vector. The magnitude is the overall distance of the vector from tail to head, and the direction is the angle at which the vector is oriented.\n",
    "\n",
    "### Calculating Magnitude\n",
    "Calculating the magnitude of the vector from its cartesian coordinates requires measuring the distance between the arbitrary starting point and the vector head point. For a two-dimensional vector, we're actually just calculating the length of the hypotenuse in a right-angled triangle - so we could simply invoke Pythagorean theorum and calculate the square root of the sum of the squares of it's components, like this:\n",
    "\n",
    "\\begin{equation}\\|\\vec{v}\\| = \\sqrt{v_{1}\\;^{2} + v_{2}\\;^{2}}\\end{equation}\n",
    "\n",
    "The notation for a vector's magnitude is to surround the vector name with vertical bars - you can use single bars (for example, |**v**|) or double bars (||**v**||). Double-bars are often used to avoid confusion with absolute values. Note that the components of the vector are indicated by subscript indices (v<sub>1</sub>, v<sub>2</sub>,...v<sub>*n*</sub>),\n",
    "\n",
    "In this case, the vector **v** has two components with values **2** and **1**, so our magnitude calculation is:\n",
    "\n",
    "\\begin{equation}\\|\\vec{v}\\| = \\sqrt{2^{2} + 1^{2}}\\end{equation}\n",
    "\n",
    "Which is:\n",
    "\n",
    "\\begin{equation}\\|\\vec{v}\\| = \\sqrt{4 + 1}\\end{equation}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{equation}\\|\\vec{v}\\| = \\sqrt{5} \\approx 2.24\\end{equation}\n",
    "\n",
    "You can run the following Python code to get a more precise result (note that the elements of a numpy array are zero-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "vMag = math.sqrt(v[0]**2 + v[1]**2)\n",
    "print (vMag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calculation works for vectors of any dimensionality - you just take the square root of the sum of the squared components:\n",
    "\n",
    "\\begin{equation}\\|\\vec{v}\\| = \\sqrt{v_{1}\\;^{2} + v_{2}\\;^{2} ... + v_{n}\\;^{2}}\\end{equation}\n",
    "\n",
    "In Python, *numpy* provides a linear algebra library named **linalg** that makes it easier to work with vectors - you can use the **norm** function in the following code to calculate the magnitude of a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vMag = np.linalg.norm(v)\n",
    "print (vMag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Direction\n",
    "To calculate the direction, or *amplitude*, of a vector from its cartesian coordinates, you must employ a little trigonometry. We can get the angle of the vector by calculating the *inverse tangent*; sometimes known as the *arctan* (the *tangent*  calculates an angle as a ratio - the inverse tangent, or **tan<sup>-1</sup>**, expresses this in degrees).\n",
    "\n",
    "In any right-angled triangle, the tangent is calculated as the *opposite* over the *adjacent*. In a two dimensional vector, this is the *y* value over the *x* value, so for our **v** vector (2,1):\n",
    "\n",
    "\\begin{equation}tan(\\theta) = \\frac{1}{2}\\end{equation}\n",
    "\n",
    "This produces the result ***0.5***, from which we can use a calculator to calculate the inverse tangent to get the angle in degrees:\n",
    "\n",
    "\\begin{equation}\\theta = tan^{-1} (0.5) \\approx 26.57^{o}\\end{equation}\n",
    "\n",
    "Note that the direction angle is indicated as ***&theta;***.\n",
    "\n",
    "Run the following Python code to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "v = np.array([2,1])\n",
    "vTan = v[1] / v[0]\n",
    "print ('tan = ' + str(vTan))\n",
    "vAtan = math.atan(vTan)\n",
    "# atan returns the angle in radians, so convert to degrees\n",
    "print('inverse-tan = ' + str(math.degrees(vAtan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an added complication however, because if the value for *x* or *y* (or both) is negative, the orientation of the vector is not standard, and a calculator can give you the wrong tan<sup>-1</sup> value. To ensure you get the correct direction for your vector, use the following rules:\n",
    "- Both *x* and *y* are positive: Use the tan<sup>-1</sup> value.\n",
    "- *x* is negative, *y* is positive: Add 180 to the tan<sup>-1</sup> value.\n",
    "- Both *x* and *y* are negative: Add 180 to the tan<sup>-1</sup> value.\n",
    "- *x* is positive, *y* is negative: Add 360 to the tan<sup>-1</sup> value.\n",
    "\n",
    "To understand why we need to do this, think of it this way. A vector can be pointing in any direction through a 360 degree arc.  Let's break that circle into four quadrants with the x and y axis through the center. Angles can be measured from the x axis in both the positive (counter-clockwise) and negative (clockwise) directions. We'll number the quadrants in the positive (counter-clockwise) direction (which is how we measure the *positive* angle) like this:\n",
    "\n",
    "    \n",
    "\n",
    "    2 | 1\n",
    "    - o -\n",
    "    3 | 4\n",
    "\n",
    "\n",
    "OK, let's look at 4 example vectors\n",
    "\n",
    " 1. Vector [2,4] has positive values for both x and y. The line for this vector travels through the point 0,0 from quadrant 3 to quadrant 1. Tan<sup>-1</sup> of 4/2 is around 63.4 degrees, which is the positive angle from the x axis to the vector line - so this is the direction of the vector.\n",
    " 2. Vector [-2,4] has a negative x and positive y. The line for this vector travels through point 0,0 from quadrant 4 to quadrant 2. Tan<sup>-1</sup> of 4/-2 is around -64.4 degrees, which is the *negative* angle from x to the vector line; but in the wrong direction (as if the vector was travelling from quadrant 2 towards quadrant 4). So we need the opposite direction, which we get by adding 180.\n",
    " 3. Vector [-2,-4] has negative x and y. The line for the vector travels through 0,0 from quadrant 1 to quadrant 3. Tan<sup>-1</sup> of -4/-2 is around 63.4 degrees, which is the angle between the x axis and the line, but again in the opposite direction, from quadrant 3 to quadrant 1; we need to go a further 180 degrees to reflect the correct direction.\n",
    " 4. Vector [2,-4] has positive x and negative y. It travels through 0,0 from quadrant 2 to quadrant 4. Tan<sup>-1</sup> of -4/2 is around -64.4 degrees, which is the *negative* angle from the x axis to the vector line. Technically it's correct, the line is travelleing down and to the right at an angle of -63.4 degrees; but we want to express the *positive* (counter-clockwise) angle, so we add 360.\n",
    "\n",
    "\n",
    "In the previous Python code, we used the *math.**atan*** function to calculate the inverse tangent from a numeric tangent. The *numpy* library includes a similar ***arctan*** function. When working with numpy arrays, you can also use the *numpy.**arctan2*** function to return the inverse tangent of an array-based vector in *radians*, and you can use the *numpy.**degrees*** function to convert this to degrees. The ***arctan2*** function automatically makes the necessary adjustment for negative *x* and *y* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([2,1])\n",
    "print ('v: ' + str(np.degrees(np.arctan2(v[1], v[0]))))\n",
    "\n",
    "s = np.array([-3,2])\n",
    "print ('s: ' + str(np.degrees(np.arctan2(s[1], s[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Addition\n",
    "So far, we've worked with one vector at a time. What happens when you need to add two vectors.\n",
    "\n",
    "Let's take a look at an example, we already have a vector named **v**, as defined here:\n",
    "\\begin{equation}\\vec{v} = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\end{equation}\n",
    "Now let's create a second vector, and called **s** like this:\n",
    "\\begin{equation}\\vec{s} = \\begin{bmatrix}-3 \\\\ 2 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "Run the cell below to create **s** and plot it together with **v**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([2,1])\n",
    "s = np.array([-3,2])\n",
    "print (s)\n",
    "\n",
    "# Plot v and s\n",
    "vecs = np.array([v,s])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['r', 'b'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the plot that the two vectors have different directions and magnitudes. So what happens when we add them together?\n",
    "\n",
    "Here's the formula:\n",
    "\\begin{equation}\\vec{z} = \\vec{v}+\\vec{s}\\end{equation}\n",
    "\n",
    "In terms of our vector matrices, this looks like this:\n",
    "\\begin{equation}\\vec{z} = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix}-3 \\\\ 2 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "Which gives the following result:\n",
    "\\begin{equation}\\vec{z} = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix}-3 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix}-1 \\\\ 3 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "Let's verify that Python gives the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = v + s\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does that look like on our plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs = np.array([v,s,z])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['r', 'b', 'g'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on here?\n",
    "Well, we added the dimensions of **s** to the dimensions of **v** to describe a new vector **z**. Let's break that down:\n",
    "- The dimensions of **v** are (2,1), so from our starting point we move 2 units in the *x* dimension (across to the right) and 1 unit in the *y* dimension (up). In the plot, if you start at the (0,0) position, this is shown as the red arrow.\n",
    "- Then we're adding **s**, which has dimension values (-3, 2), so we move -3 units in the *x* dimension (across to the left, because it's a negative number) and then 2 units in the *y* dimension (up). On the plot, if you start at the head of the red arrow and make these moves, you'll end up at the head of the green arrow, which represents **z**.\n",
    "\n",
    "The same is true if you perform the addition operation the other way around and add **v** to **s**, the steps to create **s** are described by the blue arrow, and if you use that as the starting point for **v**, you'll end up at the head of the green arrow, which represents **z**.\n",
    "\n",
    "Note on the plot that if you simply moved the tail of the blue arrow so that it started at the head of red arrow, its head would end up in the same place as the head of the green arrow; and the same would be true if you moved tail of the red arrow to the head of the blue arrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Multiplication\n",
    "Vector multiplication can be performed in three ways:\n",
    "\n",
    "- Scalar Multiplication\n",
    "- Dot Product Multiplication\n",
    "- Cross Product Multiplication\n",
    "\n",
    "## Scalar Multiplication\n",
    "Let's start with *scalar* multiplication - in other words, multiplying a vector by a single numeric value.\n",
    "\n",
    "Suppose I want to multiply my vector by 2, which I could write like this:\n",
    "\n",
    "\\begin{equation} \\vec{w} = 2\\vec{v}\\end{equation}\n",
    "\n",
    "Note that the result of this calculation is a new vector named **w**. So how would we calculate this?\n",
    "Recall that **v** is defined like this:\n",
    "\n",
    "\\begin{equation}\\vec{v} = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "To calculate 2v, we simply need to apply the operation to each dimension value in the vector matrix, like this:\n",
    "\n",
    "\\begin{equation}\\vec{w} = \\begin{bmatrix}2 \\cdot 2 \\\\  2 \\cdot 1 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "Which gives us the following result:\n",
    "\n",
    "\\begin{equation}\\vec{w} = \\begin{bmatrix}2 \\cdot 2 \\\\  2 \\cdot 1 \\end{bmatrix} = \\begin{bmatrix}4 \\\\ 2 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "In Python, you can apply these sort of matrix operations directly to numpy arrays, so we can simply calculate **w** like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "v = np.array([2,1])\n",
    "\n",
    "w = 2 * v\n",
    "print(w)\n",
    "\n",
    "# Plot w\n",
    "origin = [0], [0]\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, *w, scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach is taken for scalar division.\n",
    "\n",
    "Try it for yourself - use the cell below to calculate a new vector named **b** based on the following definition:\n",
    "\n",
    "\\begin{equation}\\vec{b} = \\frac{\\vec{v}}{2}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = v / 2\n",
    "print(b)\n",
    "\n",
    "# Plot b\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, *b, scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Multiplication\n",
    "So we've seen how to multiply a vector by a scalar. How about multiplying two vectors together? There are actually two ways to do this depending on whether you want the result to be a *scalar product* (in other words, a number) or a *vector product* (a vector).\n",
    "\n",
    "To get a scalar product, we calculate the *dot product*. This takes a similar approach to multiplying a vector by a scalar, except that it multiplies each component pair of the vectors and sums the results. To indicate that we are performing a dot product operation, we use the &bull; operator:\n",
    "\n",
    "\\begin{equation} \\vec{v} \\cdot \\vec{s} = (v_{1} \\cdot s_{1}) + (v_{2} \\cdot s_{2}) ... + \\; (v_{n} \\cdot s_{n})\\end{equation}\n",
    "\n",
    "So for our vectors **v** (2,1) and **s** (-3,2), our calculation looks like this:\n",
    "\n",
    "\\begin{equation} \\vec{v} \\cdot \\vec{s} = (2 \\cdot -3) + (1 \\cdot 2) = -6 + 2 = -4\\end{equation}\n",
    "\n",
    "So the dot product, or scalar product, of **v** &bull; **s** is **-4**.\n",
    "\n",
    "In Python, you can use the *numpy.**dot*** function to calculate the dot product of two vector arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([2,1])\n",
    "s = np.array([-3,2])\n",
    "d = np.dot(v,s)\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3.5 and later, you can also use the **@** operator to calculate the dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([2,1])\n",
    "s = np.array([-3,2])\n",
    "d = v @ s\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cosine Rule\n",
    "An useful property of vector dot product multiplication is that we can use it to calculate the cosine of the angle between two vectors. We could write the dot products as:\n",
    "\n",
    "$$ \\vec{v} \\cdot \\vec{s} = \\|\\vec{v} \\|\\|\\vec{s}\\| \\cos (\\theta) $$ \n",
    "\n",
    "Which we can rearrange as:\n",
    "\n",
    "$$ \\cos(\\theta) = \\frac{\\vec{v} \\cdot \\vec{s}}{\\|\\vec{v} \\|\\|\\vec{s}\\|} $$\n",
    "\n",
    "So for our vectors **v** (2,1) and **s** (-3,2), our calculation looks like this:\n",
    "\n",
    "$$ \\cos(\\theta) = \\frac{(2 \\cdot-3) + (-3 \\cdot 2)}{\\sqrt{2^{2} + 1^{2}} \\times \\sqrt{-3^{2} + 2^{2}}} $$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\\cos(\\theta) = \\frac{-4}{8.0622577483}$$\n",
    "\n",
    "Which calculates to:\n",
    "\n",
    "$$\\cos(\\theta) = -0.496138938357 $$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\\theta \\approx 119.74 $$\n",
    "\n",
    "Here's that calculation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# define our vectors\n",
    "v = np.array([2,1])\n",
    "s = np.array([-3,2])\n",
    "\n",
    "# get the magnitudes\n",
    "vMag = np.linalg.norm(v)\n",
    "sMag = np.linalg.norm(s)\n",
    "\n",
    "# calculate the cosine of theta\n",
    "cos = (v @ s) / (vMag * sMag)\n",
    "\n",
    "# so theta (in degrees) is:\n",
    "theta = math.degrees(math.acos(cos))\n",
    "\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross Product Multiplication\n",
    "To get the *vector product* of multipying two vectors together, you must calculate the *cross product*. The result of this is a new vector that is at right angles to both the other vectors in 3D Euclidean space. This means that the cross-product only really makes sense when working with vectors that contain three components.\n",
    "\n",
    "For example, let's suppose we have the following vectors:\n",
    "\n",
    "\\begin{equation}\\vec{p} = \\begin{bmatrix}2 \\\\ 3 \\\\ 1 \\end{bmatrix}\\;\\; \\vec{q} = \\begin{bmatrix}1 \\\\ 2 \\\\ -2 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "To calculate the cross product of these vectors, written as **p** x **q**, we need to create a new vector (let's call it **r**) with three components (r<sub>1</sub>, r<sub>2</sub>, and r<sub>3</sub>). The values for these components are calculated like this:\n",
    "\n",
    "\\begin{equation}r_{1} = p_{2}q_{3} - p_{3}q_{2}\\end{equation}\n",
    "\\begin{equation}r_{2} = p_{3}q_{1} - p_{1}q_{3}\\end{equation}\n",
    "\\begin{equation}r_{3} = p_{1}q_{2} - p_{2}q_{1}\\end{equation}\n",
    "\n",
    "So in our case:\n",
    "\n",
    "\\begin{equation}\\vec{r} = \\vec{p} \\times \\vec{q} = \\begin{bmatrix}(3 \\cdot -2) - (1 \\cdot 2) \\\\ (1 \\cdot 1) - (2 \\cdot -2) \\\\ (2 \\cdot 2) - (3 \\cdot 1) \\end{bmatrix} = \\begin{bmatrix}-6 - 2 \\\\ 1 - -4 \\\\ 4 - 3 \\end{bmatrix} = \\begin{bmatrix}-8 \\\\ 5 \\\\ 1 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "In Python, you can use the *numpy.**cross*** function to calculate the cross product of two vector arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.array([2,3,1])\n",
    "q = np.array([1,2,-2])\n",
    "r = np.cross(p,q)\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Matrices\n",
    "In general terms, a matrix is an array of numbers that are arranged into rows and columns.\n",
    "\n",
    "## Matrices and Matrix Notation\n",
    "A matrix arranges numbers into rows and columns, like this:\n",
    "\n",
    "\\begin{equation}A = \\begin{bmatrix}\n",
    "  1 & 2 & 3 \\\\\n",
    "  4 & 5 & 6\n",
    " \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that matrices are generally named as a capital letter. We refer to the *elements* of the matrix using the lower case equivalent with a subscript row and column indicator, like this:\n",
    "\n",
    "\\begin{equation}A = \\begin{bmatrix}\n",
    "  a_{1,1} & a_{1,2} & a_{1,3} \\\\\n",
    "  a_{2,1} & a_{2,2} & a_{2,3}\n",
    " \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "In Python, you can define a matrix as a 2-dimensional *numpy.**array***, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "print (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the *numpy.**matrix*** type, which is a specialist subclass of ***array***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "M = np.matrix([[1,2,3],\n",
    "               [4,5,6]])\n",
    "print (M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some differences in behavior between ***array*** and ***matrix*** types - particularly with regards to multiplication (which we'll explore later). You can use either, but most experienced Python programmers who need to work with both vectors and matrices tend to prefer the ***array*** type for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Operations\n",
    "Matrices support common arithmetic operations.\n",
    "\n",
    "### Adding Matrices\n",
    "To add two matrices of the same size together, just add the corresponding elements in each matrix:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\end{bmatrix}+ \\begin{bmatrix}6 & 5 & 4 \\\\3 & 2 & 1\\end{bmatrix} = \\begin{bmatrix}7 & 7 & 7 \\\\7 & 7 & 7\\end{bmatrix}\\end{equation}\n",
    "\n",
    "In this example, we're adding two matrices (let's call them ***A*** and ***B***). Each matrix has two rows of three columns (so we describe them as 2x3 matrices). Adding these will create a new matrix of the same dimensions with the values a<sub>1,1</sub> + b<sub>1,1</sub>, a<sub>1,2</sub> + b<sub>1,2</sub>, a<sub>1,3</sub> + b<sub>1,3</sub>,a<sub>2,1</sub> + b<sub>2,1</sub>, a<sub>2,2</sub> + b<sub>2,2</sub>, and a<sub>2,3</sub> + b<sub>2,3</sub>. In this instance, each pair of corresponding elements(1 and 6, 2, and 5, 3 and 4, etc.) adds up to 7.\n",
    "\n",
    "Let's try that with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "B = np.array([[6,5,4],\n",
    "              [3,2,1]])\n",
    "print(A + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting Matrices\n",
    "Matrix subtraction works similarly to matrix addition:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\end{bmatrix}- \\begin{bmatrix}6 & 5 & 4 \\\\3 & 2 & 1\\end{bmatrix} = \\begin{bmatrix}-5 & -3 & -1 \\\\1 & 3 & 5\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Here's the Python code to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "B = np.array([[6,5,4],\n",
    "              [3,2,1]])\n",
    "print (A - B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conformability\n",
    "In the previous examples, we were able to add and subtract the matrices, because the *operands* (the matrices we are operating on) are ***conformable*** for the specific operation (in this case, addition or subtraction). To be conformable for addition and subtraction, the operands must have the same number of rows and columns. There are different conformability requirements for other operations, such as multiplication; which we'll explore later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Matrices\n",
    "The nagative of a matrix, is just a matrix with the sign of each element reversed:\n",
    "\n",
    "\\begin{equation}C = \\begin{bmatrix}-5 & -3 & -1 \\\\1 & 3 & 5\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}-C = \\begin{bmatrix}5 & 3 & 1 \\\\-1 & -3 & -5\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Let's see that with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "C = np.array([[-5,-3,-1],\n",
    "              [1,3,5]])\n",
    "print (C)\n",
    "print (-C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Transposition\n",
    "You can *transpose* a matrix, that is switch the orientation of its rows and columns. You indicate this with a superscript **T**, like this:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\end{bmatrix}^{T} = \\begin{bmatrix}1 & 4\\\\2 & 5\\\\3 & 6 \\end{bmatrix}\\end{equation}\n",
    "\n",
    "In Python, both *numpy.**array*** and *numpy.**matrix*** have a **T** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Matrices\n",
    "This notebook continues your exploration of matrices.\n",
    "\n",
    "## Matrix Multiplication\n",
    "Multiplying matrices is a little more complex than the operations we've seen so far. There are two cases to consider, *scalar multiplication* (multiplying a matrix by a single number), and *dot product matrix multiplication* (multiplying a matrix by another matrix.\n",
    "### Scalar Multiplication\n",
    "To multiply a matrix by a scalar value, you just multiply each element by the scalar to produce a new matrix:\n",
    "\n",
    "\\begin{equation}2 \\times \\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\end{bmatrix} = \\begin{bmatrix}2 & 4 & 6 \\\\8 & 10 & 12\\end{bmatrix}\\end{equation}\n",
    "\n",
    "In Python, you perform this calculation using the **\\*** operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "print(2 * A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product Matrix Multiplication\n",
    "To mulitply two matrices together, you need to calculate the *dot product* of rows and columns. This means multiplying each of the elements in each row of the first matrix by each of the elements in each column of the second matrix and adding the results. We perform this operation by applying the *RC* rule - always multiplying ***R***ows by ***C***olumns. For this to work, the number of ***columns*** in the first matrix must be the same as the number of ***rows*** in the second matrix so that the matrices are *conformable* for the dot product operation.\n",
    "\n",
    "Sounds confusing, right?\n",
    "\n",
    "Let's look at an example:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\end{bmatrix} \\cdot \\begin{bmatrix}9 & 8 \\\\ 7 & 6 \\\\ 5 & 4\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Note that the first matrix is 2x3, and the second matrix is 3x2. The important thing here is that the first matrix has two rows, and the second matrix has two columns. To perform the multiplication, we first take the dot product of the first ***row*** of the first matrix (1,2,3) and the first ***column*** of the second matrix (9,7,5):\n",
    "\n",
    "\\begin{equation}(1,2,3) \\cdot (9,7,5) = (1 \\times 9) + (2 \\times 7) + (3 \\times 5) = 38\\end{equation}\n",
    "\n",
    "In our resulting matrix (which will always have the same number of ***rows*** as the first matrix, and the same number of ***columns*** as the second matrix), we can enter this into the first row and first column element:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}38 & ?\\\\? & ?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "Now we can take the dot product of the first row of the first matrix and the second column of the second matrix:\n",
    "\n",
    "\\begin{equation}(1,2,3) \\cdot (8,6,4) = (1 \\times 8) + (2 \\times 6) + (3 \\times 4) = 32\\end{equation}\n",
    "\n",
    "Let's add that to our resulting matrix in the first row and second column element:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}38 & 32\\\\? & ?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "Now we can repeat this process for the second row of the first matrix and the first column of the second matrix:\n",
    "\n",
    "\\begin{equation}(4,5,6) \\cdot (9,7,5) = (4 \\times 9) + (5 \\times 7) + (6 \\times 5) = 101\\end{equation}\n",
    "\n",
    "Which fills in the next element in the result:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}38 & 32\\\\101 & ?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "Finally, we get the dot product for the second row of the first matrix and the second column of the second matrix:\n",
    "\n",
    "\\begin{equation}(4,5,6) \\cdot (8,6,4) = (4 \\times 8) + (5 \\times 6) + (6 \\times 4) = 86\\end{equation}\n",
    "\n",
    "Giving us:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}38 & 32\\\\101 & 86\\end{bmatrix} \\end{equation}\n",
    "\n",
    "In Python, you can use the *numpy.**dot*** function or the **@** operator to multiply matrices and two-dimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6]])\n",
    "B = np.array([[9,8],\n",
    "              [7,6],\n",
    "              [5,4]])\n",
    "print(np.dot(A,B))\n",
    "print(A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one case where there is a difference in behavior between *numpy.**array*** and *numpy.**matrix***, You can also use a regular multiplication (**\\***) operator with a matrix, but not with an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.matrix([[1,2,3]\n",
    "               ,[4,5,6]])\n",
    "B = np.matrix([[9,8],\n",
    "               [7,6],\n",
    "               [5,4]])\n",
    "print(A * B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, unlike with multiplication of regular scalar numbers, the order of the operands in a multiplication operation is significant. For scalar numbers, the *commmutative law* of multiplication applies, so for example:\n",
    "\n",
    "\\begin{equation}2 \\times 4 = 4 \\times 2\\end{equation}\n",
    "\n",
    "With matrix multiplication, things are different, for example:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}2 & 4 \\\\6 & 8\\end{bmatrix} \\cdot \\begin{bmatrix}1 & 3 \\\\ 5 & 7\\end{bmatrix} \\ne \\begin{bmatrix}1 & 3 \\\\ 5 & 7\\end{bmatrix} \\cdot \\begin{bmatrix}2 & 4 \\\\6 & 8\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Run the following Python code to test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2,4],\n",
    "              [6,8]])\n",
    "B = np.array([[1,3],\n",
    "              [5,7]])\n",
    "print(A @ B)\n",
    "print(B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrices\n",
    "An *identity* matrix (usually indicated by a capital **I**) is the equivalent in matrix terms of the number **1**. It always has the same number of rows as columns, and it has the value **1** in the diagonal element positions I<sub>1,1</sub>, I<sub>2,2</sub>, etc; and 0 in all other element positions. Here's an example of a 3x3 identity matrix:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{bmatrix} \\end{equation}\n",
    "\n",
    "Multiplying any matrix by an identity matrix is the same as multiplying a number by 1; the result is the same as the original value:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\\\7 & 8 & 9\\end{bmatrix} \\cdot \\begin{bmatrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{bmatrix} = \\begin{bmatrix}1 & 2 & 3 \\\\4 & 5 & 6\\\\7 & 8 & 9\\end{bmatrix} \\end{equation}\n",
    "\n",
    "If you doubt me, try the following Python code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9]])\n",
    "B = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1]])\n",
    "print(A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matrix Division\n",
    "You can't actually divide by a matrix; but when you want to divide matrices, you can take advantage of the fact that division by a given number is the same as multiplication by the reciprocal of that number. For example:\n",
    "\n",
    "\\begin{equation}6 \\div 3 = \\frac{1}{3}\\times 6 \\end{equation}\n",
    "\n",
    "In this case, <sup>1</sup>/<sub>3</sub> is the reciprocal of 3 (which as a fraction is <sup>3</sup>/<sub>1</sub> - we \"flip\" the numerator and denominator to get the reciprocal). You can also write <sup>1</sup>/<sub>3</sub> as 3<sup>-1</sup>.\n",
    "\n",
    "### Inverse of a Matrix\n",
    "For matrix division, we use a related idea; we multiply by the *inverse* of a matrix:\n",
    "\n",
    "\\begin{equation}A \\div B = A \\cdot B^{-1}\\end{equation}\n",
    "\n",
    "The inverse of B is B<sup>-1</sup> as long as the following equation is true:\n",
    "\n",
    "\\begin{equation}B \\cdot B^{-1} = B^{-1} \\cdot B = I\\end{equation}\n",
    "\n",
    "**I**, you may recall, is an *identity* matrix; the matrix equivalent of 1.\n",
    "\n",
    "So how do you calculate the inverse of a matrix? For a 2x2 matrix, you can follow this formula:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}a & b\\\\c & d\\end{bmatrix}^{-1} = \\frac{1}{ad-bc}  \\begin{bmatrix}d & -b\\\\-c & a\\end{bmatrix}\\end{equation}\n",
    "\n",
    "What happened there?\n",
    "- We swapped the positions of *a* and *d*\n",
    "- We changed the signs of *b* and *c*\n",
    "- We multiplied the resulting matrix by 1 over the *determinant* of the matrix (*ad-bc*)\n",
    "\n",
    "Let's try with some actual numbers:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}6 & 2\\\\1 & 2\\end{bmatrix}^{-1} = \\frac{1}{(6\\times2)-(2\\times1)}  \\begin{bmatrix}2 & -2\\\\-1 & 6\\end{bmatrix}\\end{equation}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}6 & 2\\\\1 & 2\\end{bmatrix}^{-1} = \\frac{1}{10}  \\begin{bmatrix}2 & -2\\\\-1 & 6\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Which gives us the result:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}6 & 2\\\\1 & 2\\end{bmatrix}^{-1} = \\begin{bmatrix}0.2 & -0.2\\\\-0.1 & 0.6\\end{bmatrix}\\end{equation}\n",
    "\n",
    "To check this, we can multiply the original matrix by its inverse to see if we get an identity matrix. This makes sense if you think about it; in the same way that 3 x <sup>1</sup>/<sub>3</sub> = 1, a matrix multiplied by its inverse results in an identity matrix:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}6 & 2\\\\1 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}0.2 & -0.2\\\\-0.1 & 0.6\\end{bmatrix} = \\begin{bmatrix}(6\\times0.2)+(2\\times-0.1) & (6\\times-0.2)+(2\\times0.6)\\\\(1\\times0.2)+(2\\times-0.1) & (1\\times-0.2)+(2\\times0.6)\\end{bmatrix} = \\begin{bmatrix}1 & 0\\\\0 & 1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Note that not every matrix has an inverse - for example, if the determinant works out to be 0, the inverse matrix is not defined.\n",
    "\n",
    "In Python, you can use the *numpy.linalg.**inv*** function to get the inverse of a matrix in an *array* or *matrix* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "B = np.array([[6,2],\n",
    "              [1,2]])\n",
    "\n",
    "print(np.linalg.inv(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the *matrix* type has an ***I*** method that returns the inverse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "B = np.matrix([[6,2],\n",
    "              [1,2]])\n",
    "\n",
    "print(B.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For larger matrices, the process to calculate the inverse is more complex. Let's explore an example based on the following matrix:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}4 & 2 & 2\\\\6 & 2 & 4\\\\2 & 2 & 8\\end{bmatrix} \\end{equation}\n",
    "\n",
    "The process to find the inverse consists of the following steps:\n",
    "\n",
    "1: Create a matrix of *minors* by calculating the *determinant* for each element in the matrix based on the elements that are <u>not</u> in the same row or column; like this:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{blue}4 & \\color{lightgray}2 & \\color{lightgray}2\\\\\\color{lightgray}6 & \\color{red}2 & \\color{red}4\\\\\\color{lightgray}2 & \\color{red}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(2\\times8) - (4\\times2) = 8\\;\\;\\;\\;\\begin{bmatrix}8 & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{lightgray}4 & \\color{blue}2 & \\color{lightgray}2\\\\\\color{red}6 & \\color{lightgray}2 & \\color{red}4\\\\\\color{red}2 & \\color{lightgray}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(6\\times8) - (4\\times2) = 40\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{lightgray}4 & \\color{lightgray}2 & \\color{blue}2\\\\\\color{red}6 & \\color{red}2 & \\color{lightgray}4\\\\\\color{red}2 & \\color{red}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(6\\times2) - (2\\times2) = 8\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{lightgray}4 & \\color{red}2 & \\color{red}2\\\\\\color{blue}6 & \\color{lightgray}2 & \\color{lightgray}4\\\\\\color{lightgray}2 & \\color{red}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(2\\times8) - (2\\times2) = 12\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & \\color{lightgray}? & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{red}4 & \\color{lightgray}2 & \\color{red}2\\\\\\color{lightgray}6 & \\color{blue}2 & \\color{lightgray}4\\\\\\color{red}2 & \\color{lightgray}2 & \\color{red}8\\end{bmatrix}\\;\\;\\;\\;(4\\times8) - (2\\times2) = 28\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & \\color{lightgray}?\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{red}4 & \\color{red}2 & \\color{lightgray}2\\\\\\color{lightgray}6 & \\color{lightgray}2 & \\color{blue}4\\\\\\color{red}2 & \\color{red}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(4\\times2) - (2\\times2) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\\\color{lightgray}? & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{lightgray}4 & \\color{red}2 & \\color{red}2\\\\\\color{lightgray}6 & \\color{red}2 & \\color{red}4\\\\\\color{blue}2 & \\color{lightgray}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(2\\times4) - (2\\times2) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & \\color{lightgray}? & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{red}4 & \\color{lightgray}2 & \\color{red}2\\\\\\color{red}6 & \\color{lightgray}2 & \\color{red}4\\\\\\color{lightgray}2 & \\color{blue}2 & \\color{lightgray}8\\end{bmatrix}\\;\\;\\;\\;(4\\times4) - (2\\times6) = 4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & 4 & \\color{lightgray}?\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}\\color{red}4 & \\color{red}2 & \\color{lightgray}2\\\\\\color{red}6 & \\color{red}2 & \\color{lightgray}4\\\\\\color{lightgray}2 & \\color{lightgray}2 & \\color{blue}8\\end{bmatrix}\\;\\;\\;\\;(4\\times2) - (2\\times6) = -4\\;\\;\\;\\;\\begin{bmatrix}8 & 40 & 8\\\\12 & 28 & 4\\\\4 & 4 & -4\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\n",
    "2: Apply *cofactors* to the matrix by switching the sign of every alternate element in the matrix of minors:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}8 & -40 & 8\\\\-12 & 28 & -4\\\\4 & -4 & -4\\end{bmatrix} \\end{equation}\n",
    "\n",
    "3: *Adjugate* by transposing elements diagonally:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}8 & \\color{green}-\\color{green}1\\color{green}2 & \\color{orange}4\\\\\\color{green}-\\color{green}4\\color{green}0 & 28 & \\color{purple}-\\color{purple}4\\\\\\color{orange}8 & \\color{purple}-\\color{purple}4 & -4\\end{bmatrix} \\end{equation}\n",
    "\n",
    "4: Multiply by 1/determinant of the original matrix. To find this, multiply each of the top row elements by their corresponding minor determinants (which we calculated earlier in the matrix of minors), and then subtract the second from the first and add the third:\n",
    "\n",
    "\\begin{equation}Determinant = (4 \\times 8) - (2 \\times 40) + (2 \\times 8) = -32\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\\frac{1}{-32}\\begin{bmatrix}8 & -12 & 4\\\\-40 & 28 & -4\\\\8 & -4 & -4\\end{bmatrix} =  \\begin{bmatrix}-0.25 & 0.375 & -0.125\\\\1.25 & -0.875 & 0.125\\\\-0.25 & 0.125 & 0.125\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Let's verify that the original matrix multiplied by the inverse results in an identity matrix:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}4 & 2 & 2\\\\6 & 2 & 4\\\\2 & 2 & 8\\end{bmatrix} \\cdot \\begin{bmatrix}-0.25 & 0.375 & -0.125\\\\1.25 & -0.875 & 0.125\\\\-0.25 & 0.125 & 0.125\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}= \\begin{bmatrix}(4\\times-0.25)+(2\\times1.25)+(2\\times-0.25) & (4\\times0.375)+(2\\times-0.875)+(2\\times0.125) & (4\\times-0.125)+(2\\times-0.125)+(2\\times0.125)\\\\(6\\times-0.25)+(2\\times1.25)+(4\\times-0.25) & (6\\times0.375)+(2\\times-0.875)+(4\\times0.125) & (6\\times-0.125)+(2\\times-0.125)+(4\\times0.125)\\\\(2\\times-0.25)+(2\\times1.25)+(8\\times-0.25) & (2\\times0.375)+(2\\times-0.875)+(8\\times0.125) & (2\\times-0.125)+(2\\times-0.125)+(8\\times0.125)\\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation}= \\begin{bmatrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{bmatrix} \\end{equation}\n",
    "\n",
    "As you can see, this can get pretty complicated - which is why we usually use a calculator or a computer program. You can run the following Python code to verify that the inverse matrix we calculated is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "B = np.array([[4,2,2],\n",
    "              [6,2,4],\n",
    "              [2,2,8]])\n",
    "\n",
    "print(np.linalg.inv(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying by an Inverse Matrix\n",
    "Now that you know how to calculate an inverse matrix, you can use that knowledge to multiply the inverse of a matrix by another matrix as an alternative to division:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}1 & 2\\\\3 & 4\\end{bmatrix} \\cdot \\begin{bmatrix}6 & 2\\\\1 & 2\\end{bmatrix}^{-1} \\end{equation}\n",
    "\n",
    "\\begin{equation}=\\begin{bmatrix}1 & 2\\\\3 & 4\\end{bmatrix} \\cdot \\begin{bmatrix}0.2 & -0.2\\\\-0.1 & 0.6\\end{bmatrix}  \\end{equation}\n",
    "\n",
    "\\begin{equation}=\\begin{bmatrix}(1\\times0.2)+(2\\times-0.1) & (1\\times-0.2)+(2\\times0.6)\\\\(3\\times0.2)+(4\\times-0.1) & (3\\times-0.2)+(4\\times0.6)\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}=\\begin{bmatrix}0 & 1\\\\0.2 & 1.8\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Here's the Python code to calculate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2],\n",
    "              [3,4]])\n",
    "\n",
    "B = np.array([[6,2],\n",
    "              [1,2]])\n",
    "\n",
    "\n",
    "C = A @ np.linalg.inv(B)\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Systems of Equations with Matrices\n",
    "One of the great things about matrices, is that they can help us solve systems of equations. For example, consider the following system of equations:\n",
    "\n",
    "\\begin{equation}2x + 4y = 18\\end{equation}\n",
    "\\begin{equation}6x + 2y = 34\\end{equation}\n",
    "\n",
    "We can write this in matrix form, like this:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}2 & 4\\\\6 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}x\\\\y\\end{bmatrix}=\\begin{bmatrix}18\\\\34\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Note that the variables (***x*** and ***y***) are  arranged as a column in one matrix, which is multiplied by a matrix containing the coefficients to produce as matrix containing the results. If you calculate the dot product on the left side, you can see clearly that this represents the original equations:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}2x + 4y\\\\6x + 2y\\end{bmatrix} =\\begin{bmatrix}18\\\\34\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Now. let's name our matrices so we can better understand what comes next:\n",
    "\n",
    "\\begin{equation}A=\\begin{bmatrix}2 & 4\\\\6 & 2\\end{bmatrix}\\;\\;\\;\\;X=\\begin{bmatrix}x\\\\y\\end{bmatrix}\\;\\;\\;\\;B=\\begin{bmatrix}18\\\\34\\end{bmatrix}\\end{equation}\n",
    "\n",
    "We already know that ***A &bull; X = B***, which arithmetically means that ***X = B &div; A***. Since we can't actually divide by a matrix, we need to multiply by the inverse; so we can find the values for our variables (*X*) like this: ***X = A<sup>-1</sup> &bull; B***\n",
    "\n",
    "So, first we need the inverse of A:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}2 & 4\\\\6 & 2\\end{bmatrix}^{-1} = \\frac{1}{(2\\times2)-(4\\times6)}  \\begin{bmatrix}2 & -4\\\\-6 & 2\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}= \\frac{1}{-20}  \\begin{bmatrix}2 & -4\\\\-6 & 2\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}=\\begin{bmatrix}-0.1 & 0.2\\\\0.3 & -0.1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Then we just multiply this with B:\n",
    "\n",
    "\\begin{equation}X = \\begin{bmatrix}-0.1 & 0.2\\\\0.3 & -0.1\\end{bmatrix} \\cdot \\begin{bmatrix}18\\\\34\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}X = \\begin{bmatrix}(-0.1 \\times 18)+(0.2 \\times 34)\\\\(0.3\\times18)+(-0.1\\times34)\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\\begin{equation}X = \\begin{bmatrix}5\\\\2\\end{bmatrix}\\end{equation}\n",
    "\n",
    "The resulting matrix (*X*) contains the values for our *x* and *y* variables, and we can check these by plugging them into the original equations:\n",
    "\n",
    "\\begin{equation}(2\\times5) + (4\\times2) = 18\\end{equation}\n",
    "\\begin{equation}(6\\times5) + (2\\times2) = 34\\end{equation}\n",
    "\n",
    "These of course simplify to:\n",
    "\n",
    "\\begin{equation}10 + 8 = 18\\end{equation}\n",
    "\\begin{equation}30 + 4 = 34\\end{equation}\n",
    "\n",
    "So our variable values are correct.\n",
    "\n",
    "Here's the Python code to do all of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2,4],\n",
    "              [6,2]])\n",
    "\n",
    "B = np.array([[18],\n",
    "              [34]])\n",
    "\n",
    "C = np.linalg.inv(A) @ B\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transformations, Eigenvectors, and Eigenvalues\n",
    "\n",
    "Matrices and vectors are used together to manipulate spatial dimensions. This has a lot of applications, including the mathematical generation of 3D computer graphics, geometric modeling, and the training and optimization of machine learning algorithms. We're not going to cover the subject exhaustively here; but we'll focus on a few key concepts that are useful to know when you plan to work with machine learning.\n",
    "\n",
    "## Linear Transformations\n",
    "You can manipulate a vector by multiplying it with a matrix. The matrix acts a function that operates on an input vector to produce a vector output. Specifically, matrix multiplications of vectors are *linear transformations* that transform the input vector into the output vector.\n",
    "\n",
    "For example, consider this matrix ***A*** and vector ***v***:\n",
    "\n",
    "$$ A = \\begin{bmatrix}2 & 3\\\\5 & 2\\end{bmatrix} \\;\\;\\;\\; \\vec{v} = \\begin{bmatrix}1\\\\2\\end{bmatrix}$$\n",
    "\n",
    "We can define a transformation ***T*** like this:\n",
    "\n",
    "$$ T(\\vec{v}) = A\\vec{v} $$\n",
    "\n",
    "To perform this transformation, we simply calculate the dot product by applying the *RC* rule; multiplying each row of the matrix by the single column of the vector:\n",
    "\n",
    "$$\\begin{bmatrix}2 & 3\\\\5 & 2\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\2\\end{bmatrix} = \\begin{bmatrix}8\\\\9\\end{bmatrix}$$\n",
    "\n",
    "Here's the calculation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([1,2])\n",
    "A = np.array([[2,3],\n",
    "              [5,2]])\n",
    "\n",
    "t = A@v\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, both the input vector and the output vector have 2 components - in other words, the transformation takes a 2-dimensional vector and produces a new 2-dimensional vector; which we can indicate like this:\n",
    "\n",
    "$$ T: \\rm I\\!R^{2} \\to \\rm I\\!R^{2} $$\n",
    "\n",
    "Note that the output vector may have a different number of dimensions from the input vector; so the matrix function might transform the vector from one space to another - or in notation, ${\\rm I\\!R}$<sup>n</sup> -> ${\\rm I\\!R}$<sup>m</sup>.\n",
    "\n",
    "For example, let's redefine matrix ***A***, while retaining our original definition of vector ***v***:\n",
    "\n",
    "$$ A = \\begin{bmatrix}2 & 3\\\\5 & 2\\\\1 & 1\\end{bmatrix} \\;\\;\\;\\; \\vec{v} = \\begin{bmatrix}1\\\\2\\end{bmatrix}$$\n",
    "\n",
    "Now if we once again define ***T*** like this:\n",
    "\n",
    "$$ T(\\vec{v}) = A\\vec{v} $$\n",
    "\n",
    "We apply the transformation like this:\n",
    "\n",
    "$$\\begin{bmatrix}2 & 3\\\\5 & 2\\\\1 & 1\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\2\\end{bmatrix} = \\begin{bmatrix}8\\\\9\\\\3\\end{bmatrix}$$\n",
    "\n",
    "So now, our transformation transforms the vector from 2-dimensional space to 3-dimensional space:\n",
    "\n",
    "$$ T: \\rm I\\!R^{2} \\to \\rm I\\!R^{3} $$\n",
    "\n",
    "Here it is in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v = np.array([1,2])\n",
    "A = np.array([[2,3],\n",
    "              [5,2],\n",
    "              [1,1]])\n",
    "\n",
    "t = A@v\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v = np.array([1,2])\n",
    "A = np.array([[1,2],\n",
    "              [2,1]])\n",
    "\n",
    "t = A@v\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations of Magnitude and Amplitude\n",
    "\n",
    "When you multiply a vector by a matrix, you transform it in at least one of the following two ways:\n",
    "* Scale the length (*magnitude*) of the matrix to make it longer or shorter\n",
    "* Change the direction (*amplitude*) of the matrix\n",
    "\n",
    "For example consider the following matrix and vector:\n",
    "\n",
    "$$ A = \\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\;\\;\\;\\; \\vec{v} = \\begin{bmatrix}1\\\\0\\end{bmatrix}$$\n",
    "\n",
    "As before, we transform the vector ***v*** by multiplying it with the matrix ***A***:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\0\\end{bmatrix}\\end{equation}\n",
    "\n",
    "In this case, the resulting vector has changed in length (*magnitude*), but has not changed its direction (*amplitude*).\n",
    "\n",
    "Let's visualize that in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([1,0])\n",
    "A = np.array([[2,0],\n",
    "              [0,2]])\n",
    "\n",
    "t = A@v\n",
    "print (t)\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([t,v])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original vector ***v*** is shown in orange, and the transformed vector ***t*** is shown in blue - note that ***t*** has the same direction (*amplitude*) as ***v*** but a greater length (*magnitude*).\n",
    "\n",
    "Now let's use a different matrix to transform the vector ***v***:\n",
    "\\begin{equation}\\begin{bmatrix}0 & -1\\\\1 & 0\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}0\\\\1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "This time, the resulting vector has been changed to a different amplitude, but has the same magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([1,0])\n",
    "A = np.array([[0,-1],\n",
    "              [1,0]])\n",
    "\n",
    "t = A@v\n",
    "print (t)\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([v,t])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'blue'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see change the matrix one more time:\n",
    "\\begin{equation}\\begin{bmatrix}2 & 1\\\\1 & 2\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "Now our resulting vector has been transformed to a new amplitude *and* magnitude - the transformation has affected both direction and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([1,0])\n",
    "A = np.array([[2,1],\n",
    "              [1,2]])\n",
    "\n",
    "t = A@v\n",
    "print (t)\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([v,t])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'blue'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afine Transformations\n",
    "An Afine transformation multiplies a vector by a matrix and adds an offset vector, sometimes referred to as *bias*; like this:\n",
    "\n",
    "$$T(\\vec{v}) = A\\vec{v} + \\vec{b}$$\n",
    "\n",
    "For example:\n",
    "\n",
    "\\begin{equation}\\begin{bmatrix}5 & 2\\\\3 & 1\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\1\\end{bmatrix} + \\begin{bmatrix}-2\\\\-6\\end{bmatrix} = \\begin{bmatrix}5\\\\-2\\end{bmatrix}\\end{equation}\n",
    "\n",
    "This kind of transformation is actually the basis of linear regression, which is a core foundation for machine learning. The matrix defines the *features*, the first vector is the *coefficients*, and the bias vector is the *intercept*.\n",
    "\n",
    "here's an example of an Afine transformation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([1,1])\n",
    "A = np.array([[5,2],\n",
    "              [3,1]])\n",
    "b = np.array([-2,-6])\n",
    "\n",
    "t = A@v + b\n",
    "print (t)\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([v,t])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'blue'], scale=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvectors and Eigenvalues\n",
    "So we can see that when you transform a vector using a matrix, we change its direction, length, or both. When the transformation only affects scale (in other words, the output vector has a different magnitude but the same amplitude as the input vector), the matrix multiplication for the transformation is the equivalent operation as some scalar multiplication of the vector.\n",
    "\n",
    "For example, earlier we examined the following transformation that dot-mulitplies a vector by a matrix:\n",
    "\n",
    "$$\\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\0\\end{bmatrix}$$\n",
    "\n",
    "You can achieve the same result by mulitplying the vector by the scalar value ***2***:\n",
    "\n",
    "$$2 \\times \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\0\\end{bmatrix}$$\n",
    "\n",
    "The following python performs both of these calculation and shows the results, which are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "v = np.array([1,0])\n",
    "A = np.array([[2,0],\n",
    "              [0,2]])\n",
    "\n",
    "t1 = A@v\n",
    "print (t1)\n",
    "t2 = 2*v\n",
    "print (t2)\n",
    "\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,1,1)\n",
    "# Plot v and t1\n",
    "vecs = np.array([t1,v])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()\n",
    "a=fig.add_subplot(1,2,1)\n",
    "# Plot v and t2\n",
    "vecs = np.array([t2,v])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases like these, where a matrix transformation is the equivelent of a scalar-vector multiplication, the scalar-vector pairs that correspond to the matrix are known respectively as eigenvalues and eigenvectors. We generally indicate eigenvalues using the Greek letter lambda (&lambda;), and the formula that defines eigenvalues and eigenvectors with respect to a transformation is:\n",
    "\n",
    "$$ T(\\vec{v}) = \\lambda\\vec{v}$$\n",
    "\n",
    "Where the vector ***v*** is an eigenvector and the value ***&lambda;*** is an eigenvalue for transformation ***T***.\n",
    "\n",
    "When the transformation ***T*** is represented as a matrix multiplication, as in this case where the transformation is represented by matrix ***A***:\n",
    "\n",
    "$$ T(\\vec{v}) = A\\vec{v} = \\lambda\\vec{v}$$\n",
    "\n",
    "Then  ***v*** is an eigenvector and ***&lambda;*** is an eigenvalue of ***A***.\n",
    "\n",
    "A matrix can have multiple eigenvector-eigenvalue pairs, and you can calculate them manually. However, it's generally easier to use a tool or programming language. For example, in Python you can use the ***linalg.eig*** function, which returns an array of eigenvalues and a matrix of the corresponding eigenvectors for the specified matrix.\n",
    "\n",
    "Here's an example that returns the eigenvalue and eigenvector pairs for the following matrix:\n",
    "\n",
    "$$A=\\begin{bmatrix}2 & 0\\\\0 & 3\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2,0],\n",
    "              [0,3]])\n",
    "eVals, eVecs = np.linalg.eig(A)\n",
    "print(eVals)\n",
    "print(eVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are two eigenvalue-eigenvector pairs for this matrix, as shown here:\n",
    "\n",
    "$$ \\lambda_{1} = 2, \\vec{v_{1}} = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}  \\;\\;\\;\\;\\;\\; \\lambda_{2} = 3, \\vec{v_{2}} = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} $$\n",
    "\n",
    "Let's verify that multiplying each eigenvalue-eigenvector pair corresponds to the dot-product of the eigenvector and the matrix. Here's the first pair:\n",
    "\n",
    "$$ 2 \\times \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 0\\\\0 & 3\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix} $$\n",
    "\n",
    "So far so good. Now let's check the second pair:\n",
    "\n",
    "$$ 3 \\times \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 3\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 0\\\\0 & 3\\end{bmatrix} \\cdot \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 3\\end{bmatrix} $$\n",
    "\n",
    "So our eigenvalue-eigenvector scalar multiplications do indeed correspond to our matrix-eigenvector dot-product transformations.\n",
    "\n",
    "Here's the equivalent code in Python, using the ***eVals*** and ***eVecs*** variables you generated in the previous code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = eVecs[:,0]\n",
    "lam1 = eVals[0]\n",
    "\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "print('-------')\n",
    "\n",
    "print('lam1: ' + str(lam1))\n",
    "print ('v1: ' + str(vec1))\n",
    "print ('Av1: ' + str(A@vec1))\n",
    "print ('lam1 x v1: ' + str(lam1*vec1))\n",
    "\n",
    "print('-------')\n",
    "\n",
    "vec2 = eVecs[:,1]\n",
    "lam2 = eVals[1]\n",
    "\n",
    "print('lam2: ' + str(lam2))\n",
    "print ('v2: ' + str(vec2))\n",
    "print ('Av2: ' + str(A@vec2))\n",
    "print ('lam2 x v2: ' + str(lam2*vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code to visualize these transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = lam1*vec1\n",
    "print (t1)\n",
    "t2 = lam2*vec2\n",
    "print (t2)\n",
    "\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,1,1)\n",
    "# Plot v and t1\n",
    "vecs = np.array([t1,vec1])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()\n",
    "a=fig.add_subplot(1,2,1)\n",
    "# Plot v and t2\n",
    "vecs = np.array([t2,vec2])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, earlier we examined the following matrix transformation:\n",
    "\n",
    "$$\\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\cdot  \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\0\\end{bmatrix}$$\n",
    "\n",
    "And we saw that you can achieve the same result by mulitplying the vector by the scalar value ***2***:\n",
    "\n",
    "$$2 \\times \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}2\\\\0\\end{bmatrix}$$\n",
    "\n",
    "This works because the scalar value 2 and the vector (1,0) are an eigenvalue-eigenvector pair for this matrix.\n",
    "\n",
    "Let's use Python to determine the eigenvalue-eigenvector pairs for this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2,0],\n",
    "              [0,2]])\n",
    "eVals, eVecs = np.linalg.eig(A)\n",
    "print(eVals)\n",
    "print(eVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again, there are two eigenvalue-eigenvector pairs for this matrix, as shown here:\n",
    "\n",
    "$$ \\lambda_{1} = 2, \\vec{v_{1}} = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}  \\;\\;\\;\\;\\;\\; \\lambda_{2} = 2, \\vec{v_{2}} = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} $$\n",
    "\n",
    "Let's verify that multiplying each eigenvalue-eigenvector pair corresponds to the dot-product of the eigenvector and the matrix. Here's the first pair:\n",
    "\n",
    "$$ 2 \\times \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix} $$\n",
    "\n",
    "Well, we already knew that. Now let's check the second pair:\n",
    "\n",
    "$$ 2 \\times \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 0\\\\0 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2\\end{bmatrix} $$\n",
    "\n",
    "Now let's use Pythonto verify and plot these transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = eVecs[:,0]\n",
    "lam1 = eVals[0]\n",
    "\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "print('-------')\n",
    "\n",
    "print('lam1: ' + str(lam1))\n",
    "print ('v1: ' + str(vec1))\n",
    "print ('Av1: ' + str(A@vec1))\n",
    "print ('lam1 x v1: ' + str(lam1*vec1))\n",
    "\n",
    "print('-------')\n",
    "\n",
    "vec2 = eVecs[:,1]\n",
    "lam2 = eVals[1]\n",
    "\n",
    "print('lam2: ' + str(lam2))\n",
    "print ('v2: ' + str(vec2))\n",
    "print ('Av2: ' + str(A@vec2))\n",
    "print ('lam2 x v2: ' + str(lam2*vec2))\n",
    "\n",
    "\n",
    "# Plot the resulting vectors\n",
    "t1 = lam1*vec1\n",
    "t2 = lam2*vec2\n",
    "\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,1,1)\n",
    "# Plot v and t1\n",
    "vecs = np.array([t1,vec1])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()\n",
    "a=fig.add_subplot(1,2,1)\n",
    "# Plot v and t2\n",
    "vecs = np.array([t2,vec2])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one more, slightly more complex example. Here's our matrix:\n",
    "\n",
    "$$\\begin{bmatrix}2 & 1\\\\1 & 2\\end{bmatrix}$$\n",
    "\n",
    "Let's get the eigenvalue and eigenvector pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2,1],\n",
    "              [1,2]])\n",
    "\n",
    "eVals, eVecs = np.linalg.eig(A)\n",
    "print(eVals)\n",
    "print(eVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the eigenvalue-eigenvector pairs are:\n",
    "\n",
    "$$ \\lambda_{1} = 3, \\vec{v_{1}} = \\begin{bmatrix}0.70710678 \\\\ 0.70710678\\end{bmatrix}  \\;\\;\\;\\;\\;\\; \\lambda_{2} = 1, \\vec{v_{2}} = \\begin{bmatrix}-0.70710678 \\\\ 0.70710678\\end{bmatrix} $$\n",
    "\n",
    "So let's check the first pair:\n",
    "\n",
    "$$ 3 \\times \\begin{bmatrix}0.70710678 \\\\ 0.70710678\\end{bmatrix} = \\begin{bmatrix}2.12132034 \\\\ 2.12132034\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 1\\\\0 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}0.70710678 \\\\ 0.70710678\\end{bmatrix} = \\begin{bmatrix}2.12132034 \\\\ 2.12132034\\end{bmatrix} $$\n",
    "\n",
    "Now let's check the second pair:\n",
    "\n",
    "$$ 1 \\times \\begin{bmatrix}-0.70710678 \\\\ 0.70710678\\end{bmatrix} = \\begin{bmatrix}-0.70710678\\\\0.70710678\\end{bmatrix}  \\;\\;\\;and\\;\\;\\; \\begin{bmatrix}2 & 1\\\\1 & 2\\end{bmatrix} \\cdot \\begin{bmatrix}-0.70710678 \\\\ 0.70710678\\end{bmatrix} = \\begin{bmatrix}-0.70710678\\\\0.70710678\\end{bmatrix} $$\n",
    "\n",
    "With more complex examples like this, it's generally easier to do it with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = eVecs[:,0]\n",
    "lam1 = eVals[0]\n",
    "\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "print('-------')\n",
    "\n",
    "print('lam1: ' + str(lam1))\n",
    "print ('v1: ' + str(vec1))\n",
    "print ('Av1: ' + str(A@vec1))\n",
    "print ('lam1 x v1: ' + str(lam1*vec1))\n",
    "\n",
    "print('-------')\n",
    "\n",
    "vec2 = eVecs[:,1]\n",
    "lam2 = eVals[1]\n",
    "\n",
    "print('lam2: ' + str(lam2))\n",
    "print ('v2: ' + str(vec2))\n",
    "print ('Av2: ' + str(A@vec2))\n",
    "print ('lam2 x v2: ' + str(lam2*vec2))\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "t1 = lam1*vec1\n",
    "t2 = lam2*vec2\n",
    "\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,1,1)\n",
    "# Plot v and t1\n",
    "vecs = np.array([t1,vec1])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()\n",
    "a=fig.add_subplot(1,2,1)\n",
    "# Plot v and t2\n",
    "vecs = np.array([t2,vec2])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['blue', 'orange'], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigendecomposition\n",
    "So we've learned a little about eigenvalues and eigenvectors; but you may be wondering what use they are. Well, one use for them is to help decompose transformation matrices.\n",
    "\n",
    "Recall that previously we found that a matrix transformation of a vector changes its magnitude, amplitude, or both. Without getting too technical about it, we need to remember that vectors can exist in any spatial orientation, or *basis*; and the same transformation can be applied in different *bases*.\n",
    "\n",
    "We can decompose a matrix using the following formula:\n",
    "\n",
    "$$A = Q \\Lambda Q^{-1}$$\n",
    "\n",
    "Where ***A*** is a trasformation that can be applied to a vector in its current base, ***Q*** is a matrix of eigenvectors that defines a change of basis, and ***&Lambda;*** is a matrix with eigenvalues on the diagonal that defines the same linear transformation as ***A*** in the base defined by ***Q***.\n",
    "\n",
    "Let's look at these in some more detail. Consider this matrix:\n",
    "\n",
    "$$A=\\begin{bmatrix}3 & 2\\\\1 & 0\\end{bmatrix}$$\n",
    "\n",
    "***Q*** is a matrix in which each column is an eigenvector of ***A***; which as we've seen previously, we can calculate using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[3,2],\n",
    "              [1,0]])\n",
    "\n",
    "l, Q = np.linalg.eig(A)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for matrix ***A***, ***Q*** is the following matrix:\n",
    "\n",
    "$$Q=\\begin{bmatrix}0.96276969 & -0.48963374\\\\0.27032301 & 0.87192821\\end{bmatrix}$$\n",
    "\n",
    "***&Lambda;*** is a matrix that contains the eigenvalues for ***A*** on the diagonal, with zeros in all other elements; so for a 2x2 matrix, &Lambda; will look like this:\n",
    "\n",
    "$$\\Lambda=\\begin{bmatrix}\\lambda_{1} & 0\\\\0 & \\lambda_{2}\\end{bmatrix}$$\n",
    "\n",
    "In our Python code, we've already used the ***linalg.eig*** function to return the array of eigenvalues for ***A*** into the variable ***l***, so now we just need to format that as a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.diag(l)\n",
    "print (L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ***&Lambda;*** is the following matrix:\n",
    "\n",
    "$$\\Lambda=\\begin{bmatrix}3.56155281 & 0\\\\0 & -0.56155281\\end{bmatrix}$$\n",
    "\n",
    "Now we just need to find ***Q<sup>-1</sup>***, which is the inverse of ***Q***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qinv = np.linalg.inv(Q)\n",
    "print(Qinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse of ***Q*** then, is:\n",
    "\n",
    "$$Q^{-1}=\\begin{bmatrix}0.89720673 & 0.50382896\\\\-0.27816009 & 0.99068183\\end{bmatrix}$$\n",
    "\n",
    "So what does that mean? Well, it means that we can decompose the transformation of *any* vector multiplied by matrix ***A*** into the separate operations ***Q&Lambda;Q<sup>-1</sup>***:\n",
    "\n",
    "$$A\\vec{v} = Q \\Lambda Q^{-1}\\vec{v}$$\n",
    "\n",
    "To prove this, let's take vector ***v***:\n",
    "\n",
    "$$\\vec{v} = \\begin{bmatrix}1\\\\3\\end{bmatrix} $$\n",
    "\n",
    "Our matrix transformation using ***A*** is:\n",
    "\n",
    "$$\\begin{bmatrix}3 & 2\\\\1 & 0\\end{bmatrix} \\cdot \\begin{bmatrix}1\\\\3\\end{bmatrix} $$\n",
    "\n",
    "So let's show the results of that using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,3])\n",
    "t = A@v\n",
    "\n",
    "print(t)\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([v,t])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'b'], scale=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's do the same thing using the ***Q&Lambda;Q<sup>-1</sup>*** sequence of operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t = (Q@(L@(Qinv)))@v\n",
    "\n",
    "# Plot v and t\n",
    "vecs = np.array([v,t])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'b'], scale=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ***A*** and ***Q&Lambda;Q<sup>-1</sup>*** are equivalent.\n",
    "\n",
    "If we view the intermediary stages of the decomposed transformation, you can see the transformation using ***A*** in the original base for ***v*** (orange to blue) and the transformation using ***&Lambda;*** in the change of basis decribed by ***Q*** (red to magenta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t1 = Qinv@v\n",
    "t2 = L@t1\n",
    "t3 = Q@t2\n",
    "\n",
    "# Plot the transformations\n",
    "vecs = np.array([v,t1, t2, t3])\n",
    "origin = [0], [0]\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0))\n",
    "plt.quiver(*origin, vecs[:,0], vecs[:,1], color=['orange', 'red', 'magenta', 'blue'], scale=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from this visualization, it should be apparent that the transformation ***Av*** can be performed by changing the basis for ***v*** using ***Q*** (from orange to red in the above plot) applying the equivalent linear transformation in that base using ***&Lambda;*** (red to magenta), and switching back to the original base using ***Q<sup>-1</sup>*** (magenta to blue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank of a Matrix\n",
    "\n",
    "The **rank** of a square matrix is the number of non-zero eigenvalues of the matrix. A **full rank** matrix has the same number of non-zero eigenvalues as the dimension of the matrix. A **rank-deficient** matrix has fewer non-zero eigenvalues as dimensions. The inverse of a rank deficient matrix is singular and so does not exist (this is why in a previous notebook we noted that some matrices have no inverse).\n",
    "\n",
    "Consider the following matrix ***A***:\n",
    "\n",
    "$$A=\\begin{bmatrix}1 & 2\\\\4 & 3\\end{bmatrix}$$\n",
    "\n",
    "Let's find its eigenvalues (***&Lambda;***):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1,2],\n",
    "              [4,3]])\n",
    "l, Q = np.linalg.eig(A)\n",
    "L = np.diag(l)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Lambda=\\begin{bmatrix}-1 & 0\\\\0 & 5\\end{bmatrix}$$\n",
    "\n",
    "This matrix has full rank. The dimensions of the matrix is 2. There are two non-zero eigenvalues. \n",
    "\n",
    "Now consider this matrix:\n",
    "\n",
    "$$B=\\begin{bmatrix}3 & -3 & 6\\\\2 & -2 & 4\\\\1 & -1 & 2\\end{bmatrix}$$\n",
    "\n",
    "Note that the second and third columns are just scalar multiples of the first column.\n",
    "\n",
    "Let's examine it's eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[3,-3,6],\n",
    "              [2,-2,4],\n",
    "              [1,-1,2]])\n",
    "lb, Qb = np.linalg.eig(B)\n",
    "Lb = np.diag(lb)\n",
    "print(Lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Lambda=\\begin{bmatrix}3 & 0& 0\\\\0 & -6\\times10^{-17} & 0\\\\0 & 0 & 3.6\\times10^{-16}\\end{bmatrix}$$\n",
    "\n",
    "Note that matrix has only 1 non-zero eigenvalue. The other two eigenvalues are so extremely small as to be effectively zero. This is an example of a rank-deficient matrix; and as such, it has no inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse of a Square Full Rank Matrix\n",
    "You can calculate the inverse of a square full rank matrix by using the following formula:\n",
    "\n",
    "$$A^{-1} = Q \\Lambda^{-1} Q^{-1}$$\n",
    "\n",
    "Let's apply this to matrix ***A***:\n",
    "\n",
    "$$A=\\begin{bmatrix}1 & 2\\\\4 & 3\\end{bmatrix}$$\n",
    "\n",
    "Let's find the matrices for ***Q***, ***&Lambda;<sup>-1</sup>***, and ***Q<sup>-1</sup>***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1,2],\n",
    "              [4,3]])\n",
    "\n",
    "l, Q = np.linalg.eig(A)\n",
    "L = np.diag(l)\n",
    "print(Q)\n",
    "Linv = np.linalg.inv(L)\n",
    "Qinv = np.linalg.inv(Q)\n",
    "print(Linv)\n",
    "print(Qinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "$$A^{-1}=\\begin{bmatrix}-0.70710678 & -0.4472136\\\\0.70710678 & -0.89442719\\end{bmatrix}\\cdot\\begin{bmatrix}-1 & -0\\\\0 & 0.2\\end{bmatrix}\\cdot\\begin{bmatrix}-0.94280904 & 0.47140452\\\\-0.74535599 & -0.74535599\\end{bmatrix}$$\n",
    "\n",
    "Let's calculate that in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ainv = (Q@(Linv@(Qinv)))\n",
    "print(Ainv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the result:\n",
    "\n",
    "$$A^{-1}=\\begin{bmatrix}-0.6 & 0.4\\\\0.8 & -0.2\\end{bmatrix}$$\n",
    "\n",
    "We can apply the ***np.linalg.inv*** function directly to ***A*** to verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.inv(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
